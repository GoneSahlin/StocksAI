{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StocksAI Project Write-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "The goal of this project is to generate predictions on how much a stock price will increase or decrease over the next day. It takes the past ten days of data and uses that to predict one day into the future. The purpose of this tool is to make it easier for the average investor to make decisions on which stocks to invest in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Plan\n",
    "\n",
    "Initially, I planned to implement the different components of the project like so:\n",
    "| Component | Tools |\n",
    "| --------- | ------- |\n",
    "| ML Model | Python, TensorFlow |\n",
    "| Data Collection | Python, AWS Lambda |\n",
    "| Scheduler | AWS CloudWatch |\n",
    "| Database | postgres, AWS RDS |\n",
    "| Web App | Python, AWS Amplify |\n",
    "\n",
    "While developing the project, many of these decisions were changed, shown in **bold**:\n",
    "| Component | Initial Tools | Final Tools |\n",
    "| --------- | ------- | --- |\n",
    "| ML Model | Python, TensorFlow | Python, TensorFlow |\n",
    "| Data Collection | Python, AWS Lambda | Python, AWS Lambda |\n",
    "| Scheduler | AWS CloudWatch | **AWS EventBridge** |\n",
    "| Database | postgres, AWS RDS | **AWS S3** |\n",
    "| Web App | Python, AWS Amplify | Python, **Streamlit** |\n",
    "\n",
    "I decided to use AWS EventBridge instead of AWS CloudWatch because it was simpler to set up a recurring event. Instead of using a database as I initially planned, I decided that it would be easier to store the data in csv files, which are stored on AWS S3. I came to this decision because my model reads out all of the data at once for training, so it would not benefit much from a database. It would also be possible in the future to set up a database if needed. I also changed to hosting my app on Streamlit instead of AWS Amplify, because I didn't need to make my app very complicated, and just wanted it to show predictions. It was much easier to create a simple app on Streamlit than it would be on AWS Amplify."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "#### Unit Testing\n",
    "In order to test my project, I created unit tests for both the ML model and the data collector using pytest. These test ensure that each function is working as expected, and they were very helpful in finding problems with the code. Particularly for the data collection, where some of the websites would change or go down which would cause errors. The tests made it easy to find out what was going wrong. I also set up GitHub Actions to run the unit tests on every commit to ensure that the project was continuously tested.\n",
    "\n",
    "#### Model Testing\n",
    "To test the model's accuracy, I tested multiple different models to compare their results and created a chart showing their scores.\n",
    "\n",
    "![](plots/accuracy_chart.png)\n",
    "\n",
    "All of the models performed similarly, and I chose to use LSTM 1 for the final model.\n",
    "\n",
    "Potential problems leading to low accuracy:\n",
    "* Stock market inconsistencies in the last two years\n",
    "* Lack of data\n",
    "    * More stocks\n",
    "    * Longer time period\n",
    "    * More attributes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "I used GitHub Actions to make the project deploy whenever there is a commit to the main branch. This includes the AWS Lambda function being packaged and deployed, as well as the Streamlit app, which reads from the GitHub repository. The app uses the model stored on S3, which is updated whenever a new model is trained. The model can be trained with this command:\n",
    "\n",
    "\n",
    "`$ python model/src/train.py`\n",
    "\n",
    "This will train off of the latest data, and will update the app to run off of the new model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
